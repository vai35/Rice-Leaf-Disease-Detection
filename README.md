# ğŸŒ¾ Rice Leaf Disease Classification

> A deep learning project to automatically classify rice plant diseases using CNN and Transfer Learning (EfficientNetV2B3), achieving **95.65% validation accuracy**.

---

## ğŸ“Œ Table of Contents

- [Problem Statement](#problem-statement)
- [Dataset](#dataset)
- [Project Pipeline](#project-pipeline)
- [Model Architecture](#model-architecture)
- [Results & Comparison](#results--comparison)
- [Key Techniques](#key-techniques)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Conclusion](#conclusion)

---

## ğŸ§© Problem Statement

Rice is one of the world's most important food crops. Leaf diseases, if undetected, can cause massive yield losses. Manual identification is time-consuming and error-prone. This project builds an automated image classification system to detect **3 types of rice leaf diseases** from photos, enabling early intervention.

**Target Classes:**
| Class | Description |
|-------|-------------|
| ğŸ¦  Bacterial Leaf Blight | Causes water-soaked lesions on leaf edges |
| ğŸŸ¤ Brown Spot | Produces small brown circular lesions |
| âš« Leaf Smut | Creates black, raised spots on leaf surfaces |

---

## ğŸ“‚ Dataset

| Property | Value |
|----------|-------|
| Total Images | 119 |
| Train Split | 96 images (80%) |
| Validation Split | 23 images (20%) |
| Image Size | 224 Ã— 224 pixels |
| Batch Size | 16 |
| Classes | 3 |
| Source | DataMites Capstone Project |

> âš ï¸ **Challenge:** The small dataset size (119 images) makes generalization difficult, requiring heavy use of data augmentation and transfer learning.

---

## ğŸ”„ Project Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PROJECT PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Data        â”‚     â”‚  Data        â”‚     â”‚  Baseline CNN    â”‚
  â”‚  Loading &   â”‚â”€â”€â”€â”€â–¶â”‚  Augmentationâ”‚â”€â”€â”€â”€â–¶â”‚  (No Transfer    â”‚
  â”‚  Splitting   â”‚     â”‚              â”‚     â”‚   Learning)      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â”‚ Overfitting
                                                      â”‚ ~35% Accuracy
                                                      â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚               TRANSFER LEARNING PHASE                        â”‚
  â”‚                                                              â”‚
  â”‚  MobileNetV2 â”€â”€â”                                             â”‚
  â”‚  MobileNetV3   â”‚                                             â”‚
  â”‚  EfficientNetB0â”œâ”€â”€â–¶  Benchmark All Models â”€â”€â–¶ Select Best   â”‚
  â”‚  ResNet50      â”‚                                             â”‚
  â”‚  InceptionV3   â”‚                                             â”‚
  â”‚  DenseNet121   â”‚                                             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
                                                      â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚              FINE-TUNING PHASE (EfficientNetV2B3)            â”‚
  â”‚                                                              â”‚
  â”‚  â€¢ Unfreeze top 25% of layers                                â”‚
  â”‚  â€¢ Adam optimizer (lr = 1e-4)                                â”‚
  â”‚  â€¢ Early Stopping (patience=10)                              â”‚
  â”‚  â€¢ BatchNormalization + Dropout                              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  Final Model        â”‚
                                          â”‚  95.65% Val Acc     â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Model Architecture

### Baseline CNN (Custom)

```
Input (224Ã—224Ã—3)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Rescaling      â”‚  (1/255 normalization)
â”‚  (Data Aug.)    â”‚  RandomFlip, RandomRotation, RandomZoom, RandomContrast
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D(32)     â”‚  3Ã—3, ReLU
â”‚  MaxPooling2D   â”‚  2Ã—2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D(64)     â”‚  3Ã—3, ReLU
â”‚  MaxPooling2D   â”‚  2Ã—2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D(128)    â”‚  3Ã—3, ReLU
â”‚  MaxPooling2D   â”‚  2Ã—2
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flatten        â”‚
â”‚  Dense(128)     â”‚  ReLU
â”‚  Dropout        â”‚
â”‚  Dense(3)       â”‚  Softmax
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Transfer Learning Architecture (EfficientNetV2B3)

```
Input (224Ã—224Ã—3)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Augmentation  â”‚  RandomFlip, RandomRotation, RandomZoom, RandomContrast
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing      â”‚  EfficientNet-specific normalization
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EfficientNetV2B3   â”‚  Pretrained on ImageNet
â”‚  (Base Model)       â”‚  Top 25% layers unfrozen for fine-tuning
â”‚  Frozen: 75%        â”‚
â”‚  Trainable: 25%     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GlobalAveragePool2D â”‚
â”‚ BatchNormalization  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense(256, ReLU)   â”‚
â”‚  Dropout(0.2)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense(128, ReLU)   â”‚
â”‚  Dropout(0.2)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense(3, Softmax)  â”‚  Output: 3 disease classes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Results & Comparison

### Phase 1 â€” Baseline & Augmentation

| Model | Val Accuracy | Notes |
|-------|-------------|-------|
| Baseline CNN (No Aug) | ~72â€“82% | Overfitting, unstable |
| CNN + Data Augmentation | ~39% | Slow convergence |
| CNN + Aug + ReduceLROnPlateau | ~22% | Struggling with small data |

### Phase 2 â€” Transfer Learning Benchmark (All Models)

| Model | Best Val Accuracy | Training Time |
|-------|------------------|---------------|
| MobileNetV3Large | 91.30% | ~0.64 mins |
| **EfficientNetB0** | **91.30%** | **~0.45 mins** âš¡ |
| ResNet50 | 91.30% | ~0.67 mins |
| InceptionV3 | 60.87% | ~0.59 mins |
| DenseNet121 | 78.26% | ~0.76 mins |

> ğŸ’¡ **EfficientNetB0** selected as the best base â€” highest accuracy with lowest training time.

### Phase 3 â€” EfficientNet Family Fine-Tuning

| Model | Best Val Accuracy | Training Time |
|-------|------------------|---------------|
| EfficientNetV2B0 | 86.96% | ~0.89 mins |
| EfficientNetV2B1 | 82.61% | ~0.78 mins |
| EfficientNetV2B2 | 91.30% | ~0.83 mins |
| **EfficientNetV2B3** | **95.65%** | **~0.98 mins** ğŸ† |

### Final Model â€” EfficientNetV2B3 (Fine-Tuned)

| Metric | Value |
|--------|-------|
| **Validation Accuracy** | **95.65%** |
| Trainable Parameters | 6,239,801 |
| Non-Trainable Parameters | 7,123,720 |
| Total Parameters | 13,363,521 |
| Optimizer | Adam (lr = 1e-4) |
| Fine-Tuned Layers | Top 25% |

---

## ğŸ”§ Key Techniques

### Data Augmentation

```python
data_augmentation = Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.12),
    layers.RandomZoom(0.15),
    layers.RandomContrast(0.10)
])
```

| Technique | Value | Purpose |
|-----------|-------|---------|
| Random Horizontal Flip | Enabled | Simulate different orientations |
| Random Rotation | Â±12% | Rotational invariance |
| Random Zoom | Â±15% | Scale invariance |
| Random Contrast | Â±10% | Lighting variation |

### Transfer Learning Strategy

```
ImageNet Pretrained Weights
           â”‚
           â–¼
    Feature Extraction          â† Freeze all layers first
           â”‚
           â–¼
    Fine-Tuning                 â† Unfreeze top 25% of layers
           â”‚
           â–¼
    Domain Adaptation           â† Train on rice disease images
```

### Training Callbacks

| Callback | Configuration | Purpose |
|----------|--------------|---------|
| EarlyStopping | patience=10, monitor=val_accuracy | Prevent overfitting |
| ReduceLROnPlateau | patience=5, factor=0.5 | Adaptive learning rate |

---

## âš™ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/vai35/rice-leaf-disease-classification.git
cd rice-leaf-disease-classification

# Install dependencies
pip install tensorflow keras numpy matplotlib seaborn scikit-learn
```

### Requirements

| Library | Version |
|---------|---------|
| TensorFlow | â‰¥ 2.10 |
| Keras | â‰¥ 2.10 |
| NumPy | â‰¥ 1.21 |
| Matplotlib | â‰¥ 3.5 |
| Seaborn | â‰¥ 0.12 |
| scikit-learn | â‰¥ 1.0 |

---

## ğŸš€ Usage

```python
# Load and preprocess image
from tensorflow.keras.utils import load_img, img_to_array
import numpy as np

img = load_img("leaf_image.jpg", target_size=(224, 224))
img_array = img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)

# Predict
model = tf.keras.models.load_model("efficientnetv2b3_rice.h5")
predictions = model.predict(img_array)
class_names = ['Bacterial Leaf Blight', 'Brown Spot', 'Leaf Smut']
predicted_class = class_names[np.argmax(predictions)]
print(f"Predicted Disease: {predicted_class}")
```

---

## ğŸ“ Project Structure

```
rice-leaf-disease-classification/
â”‚
â”œâ”€â”€ ğŸ““ PRCP_1001_RiceLeaf.ipynb       # Main notebook
â”œâ”€â”€ ğŸ“„ README.md                       # Project documentation
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ Bacterial leaf blight/         # Class 1 images
â”‚   â”œâ”€â”€ Brown spot/                    # Class 2 images
â”‚   â””â”€â”€ Leaf smut/                     # Class 3 images
â”‚
â””â”€â”€ ğŸ“‚ models/
    â””â”€â”€ efficientnetv2b3_rice.h5       # Saved final model
```

---

## ğŸ” Why EfficientNetV2B3 Won

```
Model Selection Decision Tree
           â”‚
           â–¼
    High Accuracy?
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
   YES               NO
    â”‚                 â”‚
    â–¼                 â–¼
Fast Training?    Eliminated
    â”‚
    â”œâ”€â”€ EfficientNetB0 (91.30%, fastest)
    â”‚
    â–¼
Best in Family?
    â”‚
    â””â”€â”€ EfficientNetV2B3 (95.65%) âœ… WINNER
        â€¢ Largest receptive field
        â€¢ Best feature extraction
        â€¢ Compound scaling advantage
```

---

## ğŸ“ˆ Conclusion

| Approach | Val Accuracy | Verdict |
|----------|-------------|---------|
| Baseline CNN | ~35% | âŒ Insufficient |
| CNN + Augmentation | ~39% | âŒ Still weak |
| MobileNetV2 (Transfer) | ~86% | âœ… Good |
| EfficientNetB0 (Transfer) | 91.30% | âœ… Better |
| **EfficientNetV2B3 (Fine-Tuned)** | **95.65%** | ğŸ† **Best** |

Transfer learning with EfficientNetV2B3, combined with data augmentation and fine-tuning of the top 25% layers, proved to be the most effective strategy for this small-dataset image classification problem. The model successfully learned discriminative features for all three rice leaf diseases.

---

## ğŸ”® Future Scope

- ğŸ“Š **Expand Dataset** â€” Collect more images per class to improve generalization
- ğŸ” **Grad-CAM Visualization** â€” Highlight which leaf regions drive predictions
- ğŸ“± **Mobile Deployment** â€” Convert to TensorFlow Lite for on-field use
- ğŸŒ **Web App** â€” Deploy via Flask/FastAPI for farmer-facing diagnostics
- ğŸ¤– **More Classes** â€” Extend to detect additional rice diseases

---

## ğŸ‘¤ Author

**[Vaishnavi Shidling]**
- ğŸ”— LinkedIn: [https://www.linkedin.com/in/vaishnavi-shidling/]
- ğŸ’» GitHub: [https://github.com/vai35/]
- ğŸ“§ Email: [vaishnavishidling74@gmail.com]

---

*Built as part of the DataMites Capstone Project â€” PRCP-1001*
